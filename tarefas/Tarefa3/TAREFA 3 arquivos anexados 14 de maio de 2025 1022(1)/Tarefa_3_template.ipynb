{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0884a9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d1afd-bbf2-48d1-93be-79fbbdd43547",
   "metadata": {},
   "source": [
    "# Tarefa 3 - Neural Networks\n",
    "Third assessed coursework for the course: Técnicas e Algoritmos em Ciência de Dados\n",
    "\n",
    "This tarefa provides an exciting opportunity for students to put their knowledge acquired in class into practice, using neural networks to solve real-world problems in both classification and regression. Students will apply the concepts they have learned to build, train, and optimize neural networks, using a validation set to fine-tune hyperparameters. Students will also get used to generating important plots during training to analyse the models' behaviour. By the end of the project, students will have gained hands-on experience in implementing neural networks.\n",
    "\n",
    "## General guidelines:\n",
    "\n",
    "* This work must be entirely original. You are allowed to research documentation for specific libraries, but copying solutions from the internet or your classmates is strictly prohibited. Any such actions will result in a deduction of points for the coursework.\n",
    "* Please enter your code in the designated areas of the notebook. You can create additional code cells to experiment with, but __make sure to place your final solutions where they are requested in the notebook.__\n",
    "* Before submitting your work, make sure to rename the file to the random number that you created for the previous coursework (for example, 289479.ipynb).3\n",
    "\n",
    "## Notebook Overview:\n",
    "\n",
    "1. [Regression](#Regression) (50%)\n",
    "2. [Classification](#Classification) (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd2f07-f367-4318-96f4-56d85d13c8f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression\n",
    "## Dataset and Problem Description\n",
    "In this exercise, you will use the Energy Efficiency Prediction dataset. This dataset contains information about the energy efficiency of buildings based on eight features, including the size of the building, the orientation, and the type of building materials used. The dataset includes two targets: heating load and cooling load, which represent the energy required to heat and cool the building, respectively.\n",
    "This dataset is useful for building neural networks that predict the energy efficiency of buildings, which is an important problem in the field of sustainable energy. The dataset has been used in several machine learning research papers and provides a challenging regression problem.\n",
    "\n",
    "## Exercise Description: Energy Efficiency Prediction with Neural Networks\n",
    "In this exercise, you will use the Energy Efficiency Prediction dataset provided.\n",
    "You will build and train a neural network to predict the heating load (column labelled y1 in the dataset) and the cooling load (column labelled y2) of a building based on its energy efficiency features. \n",
    "\n",
    "**To complete this exercise, you will write code to build and train neural networks for this problem:**\n",
    "\n",
    "1. Split the dataset into training, validation, and test sets, using a 70:15:15 ratio.\n",
    "\n",
    "2. Using numpy, build a neural network that takes in the energy efficiency features as input and predicts the heating load as output. You will choose the number of neurons per layers and the number of layers, but each layer will have the same number of neurons.\n",
    "\n",
    "3. Code the forward pass and backpropagation algorithm to learn the weights of the neural network. Use the training set to train the neural network and update the weights using stochastic gradient descent. You will need to regularize your neural network using weight decay, that is, you will include a regularization term in your error function.\n",
    "\n",
    "4. Monitor the training by plotting the training and validation losses across the epochs. \n",
    "\n",
    "The performance of your neural network will be different depending on the number of layers, number of neurons per layer and the value of λ that controls the amount of weight decay. You will experiment with 3 values of λ: 0 (no weight decay), 0.001 and 0.0001.\n",
    "To choose the best network configuration and assess its performance you will:\n",
    "\n",
    "1. Calculate the loss for each configuration on the validation set.\n",
    "\n",
    "2. Choose one of the following:\n",
    "\n",
    "    - Create 3 networks for each value of the λ regularization parameter. The first network with one hidden layer and 100 neurons, the second with two hidden layers and 250 neurons per layer, and the third with three hidden layers and 150 neurons per layer. At the end you should have 9 values of the loss in the validation set. \n",
    "    - The number of layers has to be an input argument to the function you’re coding (you should use an appropriate data structure to store the hidden layers). Generate 3 [heatmaps](https://seaborn.pydata.org/generated/seaborn.heatmap.html), one for each value of the λ regularization parameter, displaying the loss on the validation set by plotting the number of layers and number of neurons in a grid. This will help you visualise the best configuration for the neural network. For each heatmap you can choose all possible nine combinations between 1 to 3 hidden layers and 100, 150 and 250 neurons per layer, but you can also choose different values. **This option gives you 7.5 bonus points.**\n",
    "__Note that for point a. you can have a variable $W_x$ for each hidden layer $x$, but for point b., in order to obtain the bonus points, you will have to have a variable number of layers and the weights $W_x$ have to be stored in an appropriate data structure of variable length according to the input argument.__\n",
    "\n",
    "**Important:**\n",
    "* Train for 50 epochs, remember that one epoch finishes when the whole training set was seen during training.\n",
    "* Set the learning rate $\\eta$ to $0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fb6bf-419a-4895-b9df-b31b5278b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de5467-3e3c-45d4-bf03-04baeaf20193",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## Dataset description: \n",
    "This is a dataset from the medical domain. It describes the problem of diagnosing coronary heart disease (CHD) via Traditional Chinese Medicine approaches. Each datapoint corresponds to a patient represented by a set of 49 features corresponding to the presence or absence of different symptoms: feelings cold or warm, sweating, etc. The 6 labels represent presence or absence of specific heart conditions: deficiency of heart qi syndrome, deficiency of heart yang syndrome, deficiency of heart yin syndrome, qi stagnation syndrome, turbid phlegm syndrome, and blood stasis syndrome.\n",
    "\n",
    "## Exercise Description: CHD49 Multi-Label Classification with Neural Networks\n",
    "In this exercise, you will build and train a neural network to predict the 6 different labels of CHD (last 6 columns of the dataset). \n",
    "\n",
    "**To complete this exercise, follow these steps:**\n",
    "\n",
    "1. Load the dataset and split it into training, validation, and test sets, using a 70:15:15 ratio. \n",
    "\n",
    "2. Build a neural network using numpy that takes in the features as input and predicts the 6 different labels. You will choose the number of neurons per layers and the number of layers, but each layer will have the same number of neurons.\n",
    "\n",
    "3. Code the forward pass and backpropagation algorithm to learn the weights of the neural network. Use the training set to train the neural network and update the weights using batch gradient descent. You will choose the number of neurons per layers and the number of layers, but each layer will have the same number of neurons.\n",
    "\n",
    "4. Monitor the training by plotting the training and validation losses across the epochs. \n",
    "\n",
    "The performance of your neural network will be different depending on the number of layers, number of neurons per layer and the value of λ that controls the amount of weight decay. You will experiment with 3 values of λ: 0 (no weight decay), 0.1 and 0.01.\n",
    "To choose the best network configuration and assess its performance you will:\n",
    "\n",
    "1. Calculate the loss for each configuration on the validation set.\n",
    "\n",
    "2. Choose one of the following:\n",
    "\n",
    "    - Create 3 networks for each value of the λ regularization parameter. The first network with one hidden layer and 100 neurons, the second with two hidden layers and 250 neurons per layer, and the third with three hidden layers and 150 neurons per layer. At the end you should have 9 values of the loss in the validation set. \n",
    "    - The number of layers has to be an input argument to the function you’re coding (you should use an appropriate data structure to store the hidden layers). Generate 3 heatmaps, one for each value of the λ regularization parameter, displaying the loss on the validation set by plotting the number of layers and number of neurons in a grid. This will help you visualise the best configuration for the neural network. For each heatmap you can choose all possible nine combinations between 1 to 3 hidden layers and 100, 150 and 250 neurons per layer, but you can also choose different values. **This option gives you 7.5 bonus points.**\n",
    "__Note that for point a. you can have a variable $W_x$ for each hidden layer $x$, but for point b., in order to obtain the bonus points, you will have to have a variable number of layers and the weights $W_x$ have to be stored in an appropriate data structure of variable length according to the input argument.__\n",
    "\n",
    "\n",
    "**Important:**\n",
    "* Train for at least 1000 epochs, remember that one epoch finishes when the whole training set was seen during training.\n",
    "* Set the learning rate $\\eta$ to $0.01$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1256e9d5-779c-4a34-96ca-44275e9efc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## your code goes here: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
