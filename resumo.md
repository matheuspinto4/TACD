# Intelig√™ncia Artificial

- `Objetivo:` contruir sistemas que executem tarefas que exigem "intelig√™ncia"
- Desde a d√©cada de 40, imediatamente, duas abordagens distintas:
    - `IA simb√≥lica`
    - `Machine Learning, ML`

## IA Simb√≥lica

O objetivo √© construir um sistema capaz de **realizar dedu√ß√µes** apartir de regras muito bem definidas.
A principal caracter√≠stica √© que depende de regras e √© **fortemente simb√≥lico**

---
### Fundamentos:

1. `L√≥gica matem√°tica`

2. `Regras de produ√ß√£o`: 
    - Formalismo para representar o conhecimento
    - IF (condition)
    THEN (action)

    - `Exemplos:`
        - Sistema de consultoria financeira
        - Sistema de diagn√≥stico m√©dico
3. `Algoritmos de busca (search algorithms):`
    - √© necess√°rio **navegar no espa√ßo de regras** (do conhecimento) para encontrar solu√ß√µes.
    - Alguns problemas podem ser enquadrados como **problemas de busca**
### Sistemas especializados (Expert Systems)

H√° uma sequ√™ncia:
- Especialista humano ->
- Engenheiro do conhecimento -> 
- Base de conhecimento <-> 
- Mecanismo de infer√™ncia <->
- Interface ->
- usu√°rio
 
---

### Sucessos na IA cl√°ssica

- `Planegamento:`
    
    - `Rovers:` que podem planejar e navegar de forma aut√¥noma em um ambiente complexo
    
    - `Rob√¥s de Armaz√©m Automatizado:` ve√≠culos guiados automaticamente (AGVs) para gerenciamento de armaz√©m.

- `Sistemas na √°rea do Direito`
    
    - `Verifica√ß√£o de conformidade`
    
    - `Split-up`
- `Sistema de apoio cl√≠nico`
- `Sistema de apoio para engenharia`

### N√£o funcionou para outras tarefas
- `Conhecimento declarativo` <-> `Conhecimento procedural`

## Machine Learning (ML)

Construir um modelo matem√°tico com `par√¢metros`
Utilizar dados para `ajustar` os `par√¢metros`

---

### Em geral, IA baseada em aprendizado de m√°quina
- Escrevemos uma `fun√ß√£o` que `resolve` nosso problema. A fun√ß√£o depende de `par√¢metros`
- Usamos os `dados` para encontrar os `par√¢metros ideias` da fun√ß√£o
- `Mais par√¢metros` necessita de `mais dados` e `computadores` mais `poderosos`  
- Quanto mais par√¢metros a nossa fun√ß√£o fica mais poderosa, implicando em melhores resultados
- Isso √© verdade para todo o campo do aprendizado de m√°quina

### √Åreas de sucesso:
- `Ve√≠culos aut√¥nomos`
- `Vis√£o computacional`
- `Processamento de linguagem natural:`
    - Reconhecimento de fala
    - Tradu√ß√£o autom√°tica
    - Sistemas de di√°logo
- `An√°lise de Dados Cient√≠ficos`

### Previs√£o vs Gera√ß√£o

Dadas fotos de cachorros e gatos, podemos querer ou classificar novas fotos ou gerar novas fotos

---

- `Classificar:` 
    - Cada foto √© um ponto no espa√ßo
    - Nossa fun√ß√£o `Corta o espa√ßo`
- `Gerar:`
    - No espa√ßo de todas as imagens poss√≠veis, cachorros e gatos formam 2 grupos distintos
    - Nossa fun√ß√£o `Modela as distribui√ß√µes`

#### Riscos da IA generativa
- `Alucina√ß√µes`
- `Inunda√ß√£o de informa√ß√µes de baixa qualidade`
- `Deepfakes, desinforma√ß√£o e manipula√ß√£o da opini√£o p√∫blica`
- `Bot ou n√£o?` 

#### Riscos da IA preditiva:
- `Falta de transpar√™ncia e explicabilidade`
    - Quais partes da imagem s√£o mais importantes para a decis√£o?
- `RObustez fraca, vulnerabilidade`
    - Mesmo um pequeno ru√≠do pode quebrar o dissernimento das classes
- `Aplica√ß√µes: Armas inteligentes, armas aut√¥nomas, vigil√¢ncia ou policiamento preditivo`

##### Vi√©s
- `O sistema s√≥ pode ser t√£o bom quanto os dados com os quais √© treinado`
- Se os dados refletirem desigualdades, esteri√≥tipos ou desequil√≠brios hist√≥ricos, o sistema de IA aprender√° e replicar√° esses preconceitos

#### Impacto ambiental
- O treinamento de grandes modelos generativos de IA requer recursos computacionais significativos

# Aprendizagem Supervisionada
## Tipos de problemas na aprendizagem supervisionada
- `Problemas de regress√£o:` a sa√≠da desejada √© um valor real
- `Problema de classifica√ß√£o:`a sa√≠da desejada √© um r√≥tulo de classe
## A ideia geral por tr√°s da aprendizagem supervisionada
- `Aprendizagem:`usar os dados para ajustar os par√¢metros `w` para que a fun√ß√£o calculada seja a que resolve o problema
- Assim, dado o conjunto de dados:
    - Escolhemos um modelo (a forma geral de **$f_w$**)
    - ajustamos (`aprendemos`) os par√¢metros de **$f_w$**
    - Usamos o modelo aprendido **$f_w$** para fazer previs√µes
- Os dados de treinamento devem ser semelhates √†queles para fazer a previs√£o

## Fun√ß√µes de erro
- Precisamos ``quantificar`` o ``erro`` do modelo com o conjunto atual de par√¢metros
**$$
SSE = \sum_{n=1}^{N} (y_n - \hat{y}_n)^2
$$
$$
\text{CrossEntropy} = -\sum_{n=1}^{N} \left[ y_n \log(\hat{y}_n) + (1 - y_n) \log(1 - \hat{y}_n) \right]
$$**

## T√©cnicas de otimiza√ß√£o

### Minimizando a fun√ß√£o de erro
- A fun√ß√£o de erro √© uma superf√≠cie definida no espa√ßo dos pesos. Geralmente √© diferenci√°vel.
### Abordagem geral
- `Procedimentos num√©ricos interativos:`
    - Escolha algum valor inicial **$w^{(0)}$** para o vetor dos pesos e, em seguida, mova-se pelo espa√ßo dos pesos usando 
**$$
w^{(t+1)} = w^{(t)} + \Delta w^{(t)}
$$**
- Diferentes algoritmos envolvem diferentes escolhas para a atualiza√ß√£o do vetor dos pesos 
**$\Delta w^{(t)}$**.
- Muitos algoritmos fazem uso de `informa√ß√µes do gradiente`.

### Otimiza√ß√£o de descida de gradiente 
*(gradient descent optimization)*
- `M√©todo batch (conjunto):` usa todo o conjunto de dados de uma s√≥ vez
**$$
w_{t+1} = w_t - \eta \cdot \nabla E(w)
$$**
    - Existem m√©todos mais eficientes do que esta simples atualiza√ß√£o
- `M√©todo estoc√°stico (Stochastic Gradient Descent):`faz uma atualiza√ß√£o com base em um datapoint por vez
**$$
w_{t+1} = w_t - \eta \cdot \nabla E_i(w)
$$**
    - onde **$\nabla E_i(w)$** √© o erro devido ao datapoint $n$
    - Cen√°rios intermedi√°rios: as atualiza√ß√µes s√£o baseadas em subconjunto de datapoints.
- Pode ser `necess√°rio` `executar` um algoritmo baseado em gradiente `v√°rias` vezes, com `diferentes` pontos de `partida`


## Medindo o desempenho da generaliza√ß√£o

### Os problemas de regress√£o e classifica√ß√£o s√£o diferentes
- `Conjunto de teste:`
    - `Problemas de regress√£o:` as coisas s√£o bastantes simples, pois s√≥ precisamos medir o qu√£o longe estamos, em m√©dia, do resultado correto.
    - `Problemas de classifica√ß√£o:` masi complicados por duas raz√µes:
        - A sa√≠da do meu sistema √© um valor que tenho que interpretar como r√≥tulo de uma classe e, dependendo de como eu interpret√°-lo, podemos ter resultados diferentes
        - Pode haver uma `diferen√ßa` na `gravidade` do `erro`, dependendo de quais classes voc√™ troca.
### Problemas de regress√£o
- Pegamos um conjunto de teste de N pontos e medimos:
    - `Sum-of-Squares Error (SSE):`
**$$
SSE = \sum_{n=1}^{N} (y_n - \hat{y}_n)^2
$$**
    -`Root-mean-square error (RMS ou RMSE):` 
**$$
RMSE = \sqrt{\frac{\sum_{n=1}^{N} (y_n - \hat{y}_n)^2}{N}}
$$**

### Problemas de classifica√ß√£o
- Como podemos avaliar o desempenho de um classificador no conjunto de teste?

#### Classifica√ß√£o Bin√°ria

##### Matriz de confus√£o
![alt text]({5D1BA776-F17A-4664-AF71-FA8C0BC258E2}.png)
- `Colunas:` **real**
- `Linhas:` **Previsto**

##### Medidas

- `Acur√°cia:` porcentagem de previs√µes corretas:
**$$
\frac
{ùëáùëÉ + ùëáùëÅ}{
ùëáùëÉ + ùëáùëÅ + ùêπùëÉ + ùêπùëÅ}
$$**
- `Precision:` a acur√°cia das previs√µes positivas (*qu√£o preciso eu sou? Qual √© a % de previ√µes corretas de todas as que prevejo como P?*):
**$$
\frac{ùëáùëÉ}
{ùëáùëÉ + ùêπùëÉ}
$$**
- `Recall (ou sensitivity):` Porcentagem de positivos que s√£o previstos corretamente(*Quanto eu "cobri" o P?*)
**$$
\frac{ùëáùëÉ}{ùëÉ} = \frac{ùëáùëÉ}
{ùëáùëÉ + ùêπùëÅ}
$$**
- `Specificity:` porcentagem de negativos que s√£o previstos corretamente (*quanto eu "cobri" o N?*)
**$$
\frac{ùëáN}{N} = \frac{ùëáN}
{TN + ùêπP}
$$**

###### Trade-off precis√£o/recall
- Quanto `maior a precis√£o` (Das medidas que consegui positivo, quantas acertei?) `menor o recall`(Das positivas, quantas acertei?) 

###### Pontua√ß√£o $F_1$
- A `m√©dia harm√¥nica` de `precission` e `recall`

- √â maior quando a precis√£o e o recall s√£o altos.

###### A curva receiver operating characteristis (ROC)
- True Positive Rate (`TPR`)
    - Taxa de `verdadeiro positivo:` √© o `recall`
    **$$
    \frac{TP}{P}
    $$**
- False Positive Rate (`FPR`)
    - Taxa de `falsos positivos`
    **$$
    \frac{FP}{N}
    $$**
- `Propriedades`:
    - Limitado no quadrado [0-1] do primeiro quadrante
    - Sempre come√ßa em (0,0):
        - Limiar = 1, `todas` as `previs√µes s√£o negativas`, `n√£o h√°` como ter `falsos negativos `ou `verdadeiros positivos`
    - Sempre termina em (1,1):
        - Limiar = 0, `Acerta `todas as `previs√µes positivas`, e `erra` todas as `previs√µes negativas`
    - Melhor ponto em (0,1): 
        - Acerta tudo
    - Desempenho aleat√≥rio na diagonal principal

    - Uma maneira de `comparar` classificadores √© medias a √°rea ¬¥
        - Um `classificador`puramente `aleat√≥rio` ter√° um `ROC AUC` igual a `0,5`

###### A curva Precision Recall (PR)
- `Recall (TPR):`% de `positivos` que s√£o `previstos corretamente`
- `Precision:`a `acur√°cia` das `previs√µes positivas` 

![alt text]({761EE6A3-8830-4E75-B729-A9E9C7DD7E51}.png)

#### Classifica√ß√£o Multiclasse
- A matriz de confus√£o √© mais complexa

### Generaliza√ß√£o
#### Avaliando o desempenho da generaliza√ß√£o
- Depois que o sistema aprender, devemos avaliar o qu√£o bom ele funcionar√° no futuro, em `novos` datapoints
#### Conjunto de treinamento, conjunto de valida√ß√£o, conjunto de teste
- Temos dois tipos de par√¢metros:
    - `Par√¢metros` que o `algoritmo ajusta`(**w**)
    - `Hiperpar√¢metros:` definidos pelo usu√°rio (eles decidem a **forma** do modelo)
- O objetivo √© a **generaliza√ß√£o**

#### Crossvalidation
- `√ötil` para quando temos `poucos dados`
- `Passos`:
    - Particionam os dados em **$S$** grupos
    - Usar **$S-1$** grupos para treinar e $1$ para teste
    - Repetir o passo 2 $S$ vezes
    - Fa√ßa a `m√©dia das pontua√ß√µes` de desempenho dos $S$ `conjuntos de teste`
    - O `resultado` ser√° o `desempenho` do `modelo`
- `Quando` $S = N$(tamanho do conjunto de dados) √© chamado de Leave-one-out `(LOO)`

### Pr√©-processamento dos dados
#### Nota sobre fun√ß√µes de base fixa
- Podemos aplicar `transforma√ß√µes` das `entradas` $\phi(x)$
- O problema de `classifica√ß√£o` pode se tornar `mais f√°cil`
![alt text]({49834335-CFF5-48FC-845D-248619B7AA39}.png)

### Taxonomia de algoritmos de aprendizado de m√°quina baseado no tipo de dados
- `A. Aprendizagem Supervisionada`:
    - `Classifica√ß√£o`
    - `Regress√£o`
- `B. Aprendizada n√£o supervisionada:`
    - `Clustering`
        -  ![alt text]({AADCFC5E-9BC2-4206-A139-4F3807BEAA93}.png)
    - `Estimativa de densidade`
        - ![alt text]({DBA39301-EB0A-4D4B-BBD2-C260610E4903}.png)
- `C. Aprendizagem semi-supervisionada`
    - `Treina` um modelo inicial com `dados rotulados` e usa-o para `prever` `r√≥tulos` em `dados n√£o rotulados`
- `D. Aprendizagem por Refor√ßo`
    - Agente
    - sequ√™ncia de `estados` e `a√ß√µes`
    - somente no final uma recompensa √© alcan√ßada
    - `Problema de atribui√ß√£o de cr√©dito:` a recompensa deve ser atribu√≠da aporpriadamente a todas as a√ß√µes que levaram a ela.   

# Modelos lineares para regress√£o
## O problema de regress√£o
- Prever o valor de vari√°veis de destino t `cont√≠nuas` dado o valor de um vetor D-dimensional `x` de vari√°veis de entrada
- Dadas $N$ observa√ß√µes {${x_n}$}, juntamente com os valores de destino $tn$ correspondentes, o objetivo √© prever o valor de t para uma novo valor de x.

# Modelos Lineares para Classifica√ß√£o

## O problema de classifica√ß√£o
- Dado um vetor de entrada $x$, atribu√≠-lo a uma das K classes discretas $C_k$ onde k = 1,...,K.
- `Classes` `s√£o disjuntas`, o espac√ßo de entrada √© dividido em `regi√µes de decis√£o`
- `Linearmente separ√°veis:` conjuntos de dados cujas classes podem ser separadas exatamente por superf√≠cies de decis√£o lineares
## Representando valores alvo
- `Duas classes (K = 2)`
    - `uma vari√°vel`, representa√ß√£o `bin√°ria` $t \isin {0,1}$
        - $t=1$ representa a classe $C_1$
        - $t=0$ representa a classe $C_2$
    - valor de `t` √© a probabilidade de que a `classe seja C1$`

- `K > 2 classes`
    - conveniente usar codifica√ß√µa 1-de-K
## 1. Aprendizagem de fun√ß√µes discriminantes
- `Um discriminante √© uma fun√ß√£o que pega um vetor de entrada x e o atribui a uma das K classes`
### A. Duas classes (K = 2)
- O discriminante linear mais simples:
**$$
y(x) = w^Tx + w_0
$$**
    - x atibu√≠do a **$C_1$** se **$y(x) >= 0$**
    - x atribu√≠do a **$C_2$** caso cont√°rio.
**$$
y(\mathbf{x}) = \tilde{\mathbf{w}}^\top \tilde{\mathbf{x}}
$$** incluindo o bias

- `Fronteira de decis√£o: ` **$y(x)=0$**, corresponde a um `hiperplano (D-1)-dimensional` no `espa√ßo` de `entrada` `D-dimensional`
- A `superf√≠cie de decis√£o` √©:
    - `perpendicular` a w
    - seu deslocamento da origem √© controlado pelo par√¢metro de bias $w_0$

- `w` controla a `orienta√ß√£o`
- o bias controla a posi√ß√£o
### B. M√∫ltiplas classes (K > 2)
- Combina√ß√µes de discriminates de 2 classes n√£o funcionam!
    - Sempre `haver√°` uma `regi√£o` em que o `discriminante` `n√£o` ser√° `capaz` de `distinguir` duas `classes` ou mais 
-` N√£o h√°` uma `solu√ß√£o` realmente `boa` para esse problema

## Discriminante Linear de Fisher
- 1) `Projete` os `pontos` `em` uma dimens√£o: **$y = w^Tx$**
- 2) Se o valor (escalar) for maior que $w_0$, ent√£o $C_1$, sen√£o $C_2$
- A quest√£o agora √© `ajustar` a `proje√ß√£o` de forma a ter os pontos pertencentes √†s `classes` diferentes `os mais separados poss√≠veis`
-  A medida mais simples da separa√ß√£o √© a `separa√ß√£o das m√©dias das classes projetadas`
- Ou podemos `maximizar` a `separa√ß√£o` e `diminuir` a `vari√¢ncia` dentro de cada `classe`
## O Perceptron
- Um modelo de duas classes:
\[
\mathbf{w}^{(\tau+1)} = \mathbf{w}^{(\tau)} + \eta \boldsymbol{\phi}_n t_n
\]
- N√£o √© garantido que  a regra de aprendizado ir√° reduzir a fun√ß√£o de erro total em cada passo
- Se o conjunto √© linearmente separ√°vel, ent√£o o prec√©ptron ir√° encontrar uma solu√ß√£o exata
-`Limitado no que pode aprender`

## O modelo geral
**\[
y(\mathbf{x}) = f\left( \mathbf{w}^\top \mathbf{x} + w_0 \right)
\]**
- Para prever r√≥tulos de classe, transformamos a fun√ß√£o linear de **w** usando uma `fun√ß√£o de ativa√ß√£o n√£o linear`**$f(.)$**
- O `modelo n√£o √© linear` nos par√¢metros
- As `superf√≠cies de decis√£o` s√£o `fun√ß√µes lineares` de ***x***, ``mesmo`` que a fun√ß√£o **$f(.)$** seja ``n√£o linear``
### Regress√£o Log√≠stica (2 classes)
**\[
y(\boldsymbol{\phi}) = \sigma \left( \mathbf{w}^\top \boldsymbol{\phi} \right)
\]**
- Um sigm√≥ide log√≠stico atuando em uma fun√ß√£o linear do vetor de caracter√≠sticas (features) **$\phi$**

**\[
E(\mathbf{w}) = - \sum_{n=1}^{N} \left\{ t_n \ln y_n + (1 - t_n) \ln (1 - y_n) \right\}
\]**
**\[
\nabla E(\mathbf{w}) = \sum_{n=1}^{N} (y_n - t_n)\boldsymbol{\phi}_n
\]**

- Para aprender **w** pode-se usar um `procedimento sequencial` onde os datapoints s√£o apresentados um de cada vez e os `vetores de peso` s√£o `atualizados` pela `descida` do `gradiente estoc√°stico`
