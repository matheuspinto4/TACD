{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425ac6e9-8919-4c06-be1c-782241f835f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f6b7d-1fdf-43a4-bd7c-03d90114d3fb",
   "metadata": {},
   "source": [
    "# Lab 8 - Multi-layer Perceptron Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353aba0-7656-45d0-961a-850e9f31f967",
   "metadata": {},
   "source": [
    "## Part I\n",
    "For this exercise you will implement a simple 2-layer perceptron (forward pass)\n",
    "\n",
    "For the first part you'll write a function that computes the forward pass of a 2-layer perecptron that predicts the prices of houses, using the usual Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7804bef6-2bd6-4d05-bc4e-f9d8325f12ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Pinto\\AppData\\Local\\Temp\\ipykernel_24492\\2042122181.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  boston = pd.read_csv('housing.txt', delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "boston = pd.read_csv('housing.txt', delim_whitespace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1af35-c3bc-48b5-916a-63bf0dd535cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "As usual, consider the MEDV as your target variable. \n",
    "* Split the data into training, validation and testing (70,15,15)% (you will need this for the next lab as we will build from this lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5bfc8-26c0-4d48-9c3c-05a9e404e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " [3.2370e-02 0.0000e+00 2.1800e+00 ... 1.8700e+01 3.9463e+02 2.9400e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = boston.values[:,:-1]\n",
    "y = boston.iloc[:,-1:]\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y,test_size=0.15, random_state=189, shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tv, y_tv, test_size=0.15/0.85 , random_state=123, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656b9eb-c272-43fb-8fe5-c095cf8461ad",
   "metadata": {},
   "source": [
    "Now you will write the function that computes the forward pass. \n",
    "* I provide here a structure that you can follow for your function, but again, feel free to modify it as you see fit.\n",
    "* Use the sigmoid function as the activation of the hidden layer.\n",
    "* Don't forget about the biases!\n",
    "* *It is up to you to think what should be the activation for the output layer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c582d2ac-e33c-47a7-8e24-fecadf38c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30eb784e-a9c5-4a70-afcd-bcaf356aa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_perceptron(X, activation, dim_input, dim_hidden, dim_output):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of a two-layer fully connected perceptron.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : a 2-dimensional array\n",
    "        the input data\n",
    "    activation : function\n",
    "        the activation function to be used for the hidden layer\n",
    "    dim_input : int\n",
    "        the dimensionality of the input layer\n",
    "    dim_hidden : int\n",
    "        the dimensionality of the hidden layer\n",
    "    dim_output : int\n",
    "        the dimensionality of the output layer\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : float\n",
    "        the output of the computation of the forward pass of the network\n",
    "    \"\"\"\n",
    "    # pushing the column of bias on X:\n",
    "    X = np.array(X, dtype=float)\n",
    "    X_bias = np.c_[X, np.ones(X.shape[0])]\n",
    "    \n",
    "    # Initializing the weights with zeros:\n",
    "    # We have two layers, so\n",
    "    W_1 = np.random.rand(dim_input+1, dim_hidden)  * 0.01\n",
    "    W_2 = np.random.rand(dim_hidden+1, dim_output) * 0.01\n",
    "    \n",
    "    A1 = X_bias @ W_1\n",
    "    Z1 = activation(A1)\n",
    "    Z1 = np.c_[Z1, np.ones(Z1.shape[0])]\n",
    "    Y = Z1 @ W_2\n",
    "\n",
    "    y_pred = Y\n",
    "    return y_pred\n",
    "\n",
    "dim_input = X_train.shape[1]\n",
    "dim_hidden = 3\n",
    "dim_output = 1\n",
    "y = two_layer_perceptron(X_test, sigmoid_activation,dim_input, dim_hidden, dim_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eb5a0-15c8-4c98-8481-5ca52a27da2d",
   "metadata": {},
   "source": [
    "Calculate the RMSE of the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc26211-91c1-47f9-8779-eb723b0c209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_foward_pass(y_pred, y_target):\n",
    "    if (type(y_target) == pd.core.frame.DataFrame):\n",
    "        y_target = np.array(y_target)\n",
    "\n",
    "    dif = y_pred - y_target\n",
    "    dif_squared = dif * dif\n",
    "    RMSE = (dif_squared.sum() / dif_squared.size) ** (1 / 2)\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6650ab-79e5-4636-a4c9-84b977c48541",
   "metadata": {},
   "source": [
    "## Part II \n",
    "\n",
    "For this exercise you will write a function that calculates the forward pass of a 2-layer perceptron that predicts the exact digit from a hand-written image, using the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfe2473-16e8-4dce-9e5b-7d5ce1154200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8f04ee-c8e6-4531-9ad4-b0e530e1f92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c49e3cd-e16a-4847-ac73-b9628f3f159a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172b3419-d470-433f-87f9-4df67e4761e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf177-1cda-4c04-8d12-090678310602",
   "metadata": {},
   "source": [
    "Again, you will split the data into training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8519363c-f7e0-43a8-ba4e-a33ab9d5b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y,test_size=0.15, random_state=189, shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tv, y_tv, test_size=0.15/0.85 , random_state=123, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4d63e-30c3-4f7d-8f6f-b12496886b5e",
   "metadata": {},
   "source": [
    "Write a function that calculates the forward pass for this multi-class classification problem.\n",
    "* You will use the sigmoid activation function for the hidden layer.\n",
    "* For the output layer you will have to write the softmax activation function (you can check the slides)\n",
    "* __Note:__ you can easily re-use the function that you coded for Part I if you do a simple modification and also include an input argument for the activation of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d68da7-1fa1-4074-b8fa-29ff1c21d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(z):\n",
    "    z = np.exp(z)\n",
    "    softmax = z / np.sum(z, axis=1, keepdims=True)\n",
    "\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28da05c-908f-4b46-87f9-e94718ca52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_multi_class(X, activation, activation_output, dim_input, dim_hidden, dim_output):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of a two-layer fully connected perceptron.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : a 2-dimensional array\n",
    "        the input data\n",
    "    activation : function\n",
    "        the activation function to be used for the hidden layer\n",
    "    activation_output : function\n",
    "        the activation function to be used for the output layer\n",
    "    dim_input : int\n",
    "        the dimensionality of the input layer\n",
    "    dim_hidden : int\n",
    "        the dimensionality of the hidden layer\n",
    "    dim_output : int\n",
    "        the dimensionality of the output layer\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : nd.array\n",
    "        the output of the computation of the forward pass of the network\n",
    "    \"\"\"\n",
    "    # pushing the column of bias on X:\n",
    "    X = np.array(X, dtype=float)\n",
    "    X_bias = np.c_[X, np.ones(X.shape[0])]\n",
    "    \n",
    "    # Initializing the weights with zeros:\n",
    "    # We have two layers, so\n",
    "    W_1 = np.random.rand(dim_input+1, dim_hidden)  * 0.01\n",
    "    W_2 = np.random.rand(dim_hidden+1, dim_output) * 0.01\n",
    "    \n",
    "    A1 = X_bias @ W_1\n",
    "    Z1 = activation(A1)\n",
    "    Z1 = np.c_[Z1, np.ones(Z1.shape[0])]\n",
    "    Y = Z1 @ W_2\n",
    "\n",
    "    y_pred = activation_output(Y)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "dim_input = X_train.shape[1]\n",
    "dim_hidden = 3\n",
    "dim_output = 10\n",
    "Y_pred = forward_pass_multi_class(X_test, sigmoid_activation,softmax_activation,dim_input, dim_hidden, dim_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b264d-1b1d-433a-98d3-eaf33b685a67",
   "metadata": {},
   "source": [
    "Lastly, calculate the error of this forward pass using the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "015f701c-f816-4208-8cdc-4ba32f03f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3024873974484343\n"
     ]
    }
   ],
   "source": [
    "def adjust_y_target(y_target):\n",
    "    if (type(y_target) == pd.core.frame.DataFrame):\n",
    "        y_target = np.array(y_target)\n",
    "    Y_target = np.zeros(shape=(y_target.shape[0], 10))\n",
    "    for l in range(y_target.shape[0]):\n",
    "        Y_target[l, y_target[l]] = 1.\n",
    "    \n",
    "    return Y_target\n",
    "\n",
    "\n",
    "def cross_entropy_loss(Y_pred, Y_target):\n",
    "    E = -np.sum(Y_target * np.log(Y_pred)) / Y_pred.shape[0]\n",
    "    return E\n",
    "\n",
    "\n",
    "Y_test = adjust_y_target(y_test)\n",
    "\n",
    "E = cross_entropy_loss(Y_pred, Y_test)\n",
    "\n",
    "print(E)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
